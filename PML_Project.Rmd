---
title: "Practical Machine Learning - Course Project"
author: "Sravan K"
date: "January 16, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load libraries
```{r, warning=FALSE, message=FALSE}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
set.seed(555)

```

## Load data
```{r}
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-testing.csv")

pml_training <- read.csv("pml-training.csv", na.strings = c("NA",""))
pml_testing <- read.csv("pml-testing.csv", na.strings = c("NA",""))
```

## Partition the training data set
Partition data - 60% in Train and 40% in Test
```{r}
inTrain <- createDataPartition(y=pml_training$classe, p=0.6, list=FALSE)
training <- pml_training[inTrain, ]
validation <- pml_training[-inTrain, ]
```

## Data cleaning
Exclude variables X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window which are just id or timestamp variables
```{r}
training <- subset(training, select = -c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window))
```
Remove variables that have missing values (NA)
```{r}
complete_data_cols <- !unlist(lapply(training, function(x) any(is.na(x))))
training<-training[,complete_data_cols]
dim(training)
```
Adjust test sets to have same columns as training set
```{r}
nm_train <- colnames(training)
validation <- validation[nm_train]
nm_train2 <- nm_train[nm_train!="classe"]
testing <- pml_testing[nm_train2]
```

## Decision Tree
Create decision tree model which will provide an interpretable prediction logic
```{r}
dt_model <- rpart(classe ~ ., data = training, method = "class")
prp(dt_model)
```

Validate the model using validation data
```{r}
predT <- predict(dt_model, validation, type="class")
confusionMatrix(validation$classe, predT)
```

## Random Forest model
Model is trained using Random Forest method.
```{r}
rf_mod <- randomForest(classe ~ ., data = training, importance = T, ntree=100)
print(rf_mod)
```

## Predict on validation dataset
Using the random forest model created above, predict for validation dataset
```{r}
predRF <- predict(rf_mod, validation, type = "class")
cnf_mat_vald <- confusionMatrix(validation$classe, predRF)
cnf_mat_vald
```

The estimated accuracy is: 99.69%. 
The estimated out of sample error is: 0.31%.

## Predict on Test Data set
Using the random forest model created above, predict for validation dataset
```{r}
predRF_Test <- predict(rf_mod, testing)
predRF_Test
```

